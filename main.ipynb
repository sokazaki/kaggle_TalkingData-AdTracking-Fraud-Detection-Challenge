{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train.csv...\n",
      "Loading test_supplement.csv...\n",
      "Preprocessing...\n",
      "Adding next_click features...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 177537505 entries, 0 to 57537504\n",
      "Data columns (total 10 columns):\n",
      "ip             uint32\n",
      "app            uint16\n",
      "device         uint16\n",
      "os             uint16\n",
      "channel        uint16\n",
      "click_time     datetime64[ns]\n",
      "hour           uint8\n",
      "next_click     float32\n",
      "next_click2    float32\n",
      "next_click3    float32\n",
      "dtypes: datetime64[ns](1), float32(3), uint16(4), uint32(1), uint8(1)\n",
      "memory usage: 6.8 GB\n",
      "None\n",
      "Adding counts features...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 177537505 entries, 0 to 177537504\n",
      "Data columns (total 13 columns):\n",
      "ip                               uint32\n",
      "app                              uint16\n",
      "device                           uint16\n",
      "os                               uint16\n",
      "channel                          uint16\n",
      "click_time                       datetime64[ns]\n",
      "hour                             uint8\n",
      "next_click                       float32\n",
      "next_click2                      float32\n",
      "next_click3                      float32\n",
      "ip_by_channel_countuniq          uint32\n",
      "ip_by_app_countuniq              uint32\n",
      "ip_device_os_by_app_countuniq    uint32\n",
      "dtypes: datetime64[ns](1), float32(3), uint16(4), uint32(4), uint8(1)\n",
      "memory usage: 8.8 GB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 177537505 entries, 0 to 177537504\n",
      "Data columns (total 15 columns):\n",
      "ip                               uint32\n",
      "app                              uint16\n",
      "device                           uint16\n",
      "os                               uint16\n",
      "channel                          uint16\n",
      "click_time                       datetime64[ns]\n",
      "hour                             uint8\n",
      "next_click                       float32\n",
      "next_click2                      float32\n",
      "next_click3                      float32\n",
      "ip_by_channel_countuniq          uint32\n",
      "ip_by_app_countuniq              uint32\n",
      "ip_device_os_by_app_countuniq    uint32\n",
      "ip_count                         uint32\n",
      "os_app_channel_count             uint32\n",
      "dtypes: datetime64[ns](1), float32(3), uint16(4), uint32(6), uint8(1)\n",
      "memory usage: 10.1 GB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 177537505 entries, 0 to 177537504\n",
      "Data columns (total 18 columns):\n",
      "ip                               uint32\n",
      "app                              uint16\n",
      "device                           uint16\n",
      "os                               uint16\n",
      "channel                          uint16\n",
      "click_time                       datetime64[ns]\n",
      "hour                             uint8\n",
      "next_click                       float32\n",
      "next_click2                      float32\n",
      "next_click3                      float32\n",
      "ip_by_channel_countuniq          uint32\n",
      "ip_by_app_countuniq              uint32\n",
      "ip_device_os_by_app_countuniq    uint32\n",
      "ip_count                         uint32\n",
      "os_app_channel_count             uint32\n",
      "ip_hour_count                    uint32\n",
      "ip_os_hour_count                 uint32\n",
      "ip_device_count                  uint32\n",
      "dtypes: datetime64[ns](1), float32(3), uint16(4), uint32(9), uint8(1)\n",
      "memory usage: 12.1 GB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 177537505 entries, 0 to 177537504\n",
      "Data columns (total 21 columns):\n",
      "ip                               uint32\n",
      "app                              uint16\n",
      "device                           uint16\n",
      "os                               uint16\n",
      "channel                          uint16\n",
      "click_time                       datetime64[ns]\n",
      "hour                             uint8\n",
      "next_click                       float32\n",
      "next_click2                      float32\n",
      "next_click3                      float32\n",
      "ip_by_channel_countuniq          uint32\n",
      "ip_by_app_countuniq              uint32\n",
      "ip_device_os_by_app_countuniq    uint32\n",
      "ip_count                         uint32\n",
      "os_app_channel_count             uint32\n",
      "ip_hour_count                    uint32\n",
      "ip_os_hour_count                 uint32\n",
      "ip_device_count                  uint32\n",
      "ip_app_os_count                  uint32\n",
      "hour_app_count                   uint32\n",
      "channel_app_count                uint32\n",
      "dtypes: datetime64[ns](1), float32(3), uint16(4), uint32(12), uint8(1)\n",
      "memory usage: 14.1 GB\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/.pyenv/versions/anaconda3-4.3.0/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 117600000\n",
      "Valid size: 2400000\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/.pyenv/versions/anaconda3-4.3.0/lib/python3.6/site-packages/lightgbm/basic.py:1036: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/Users/admin/.pyenv/versions/anaconda3-4.3.0/lib/python3.6/site-packages/lightgbm/basic.py:681: UserWarning: categorical_feature in param dict is overrided.\n",
      "  warnings.warn('categorical_feature in param dict is overrided.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[10]\ttrain's auc: 0.970205\tvalid's auc: 0.977943\n",
      "[20]\ttrain's auc: 0.976484\tvalid's auc: 0.981184\n",
      "[30]\ttrain's auc: 0.979289\tvalid's auc: 0.984237\n",
      "[40]\ttrain's auc: 0.980937\tvalid's auc: 0.985851\n",
      "[50]\ttrain's auc: 0.982034\tvalid's auc: 0.987108\n",
      "[60]\ttrain's auc: 0.982933\tvalid's auc: 0.988398\n",
      "[70]\ttrain's auc: 0.983406\tvalid's auc: 0.989111\n",
      "[80]\ttrain's auc: 0.983838\tvalid's auc: 0.989528\n",
      "[90]\ttrain's auc: 0.984143\tvalid's auc: 0.989786\n",
      "[100]\ttrain's auc: 0.984372\tvalid's auc: 0.990028\n",
      "[110]\ttrain's auc: 0.98457\tvalid's auc: 0.990104\n",
      "[120]\ttrain's auc: 0.984703\tvalid's auc: 0.990188\n",
      "[130]\ttrain's auc: 0.984848\tvalid's auc: 0.990246\n",
      "[140]\ttrain's auc: 0.984946\tvalid's auc: 0.990352\n",
      "[150]\ttrain's auc: 0.98505\tvalid's auc: 0.990394\n",
      "[160]\ttrain's auc: 0.98514\tvalid's auc: 0.990364\n",
      "[170]\ttrain's auc: 0.985225\tvalid's auc: 0.990408\n",
      "[180]\ttrain's auc: 0.985294\tvalid's auc: 0.990445\n",
      "[190]\ttrain's auc: 0.98537\tvalid's auc: 0.990525\n",
      "[200]\ttrain's auc: 0.985448\tvalid's auc: 0.990595\n",
      "[210]\ttrain's auc: 0.985509\tvalid's auc: 0.990623\n",
      "[220]\ttrain's auc: 0.985582\tvalid's auc: 0.990786\n",
      "[230]\ttrain's auc: 0.985638\tvalid's auc: 0.99084\n",
      "[240]\ttrain's auc: 0.985689\tvalid's auc: 0.990891\n",
      "[250]\ttrain's auc: 0.98575\tvalid's auc: 0.990888\n",
      "[260]\ttrain's auc: 0.985772\tvalid's auc: 0.990889\n",
      "[270]\ttrain's auc: 0.985794\tvalid's auc: 0.99089\n",
      "[280]\ttrain's auc: 0.985813\tvalid's auc: 0.990904\n",
      "[290]\ttrain's auc: 0.985833\tvalid's auc: 0.99093\n",
      "[300]\ttrain's auc: 0.985852\tvalid's auc: 0.990931\n",
      "[310]\ttrain's auc: 0.985866\tvalid's auc: 0.990942\n",
      "[320]\ttrain's auc: 0.985885\tvalid's auc: 0.990969\n",
      "[330]\ttrain's auc: 0.985903\tvalid's auc: 0.990983\n",
      "[340]\ttrain's auc: 0.98592\tvalid's auc: 0.990996\n",
      "[350]\ttrain's auc: 0.985934\tvalid's auc: 0.990999\n",
      "[360]\ttrain's auc: 0.985947\tvalid's auc: 0.99101\n",
      "[370]\ttrain's auc: 0.985967\tvalid's auc: 0.991018\n",
      "[380]\ttrain's auc: 0.985982\tvalid's auc: 0.991032\n",
      "[390]\ttrain's auc: 0.985997\tvalid's auc: 0.991035\n",
      "[400]\ttrain's auc: 0.986013\tvalid's auc: 0.991033\n",
      "[410]\ttrain's auc: 0.986029\tvalid's auc: 0.991035\n",
      "[420]\ttrain's auc: 0.986044\tvalid's auc: 0.991038\n",
      "[430]\ttrain's auc: 0.986059\tvalid's auc: 0.991044\n",
      "[440]\ttrain's auc: 0.986074\tvalid's auc: 0.991046\n",
      "[450]\ttrain's auc: 0.98609\tvalid's auc: 0.991057\n",
      "[460]\ttrain's auc: 0.986109\tvalid's auc: 0.991056\n",
      "[470]\ttrain's auc: 0.986121\tvalid's auc: 0.991049\n",
      "[480]\ttrain's auc: 0.986133\tvalid's auc: 0.991046\n",
      "[490]\ttrain's auc: 0.986149\tvalid's auc: 0.99104\n",
      "[500]\ttrain's auc: 0.986163\tvalid's auc: 0.99105\n",
      "[510]\ttrain's auc: 0.986178\tvalid's auc: 0.991051\n",
      "[520]\ttrain's auc: 0.986192\tvalid's auc: 0.991052\n",
      "[530]\ttrain's auc: 0.986207\tvalid's auc: 0.991076\n",
      "[540]\ttrain's auc: 0.986218\tvalid's auc: 0.99109\n",
      "[550]\ttrain's auc: 0.986231\tvalid's auc: 0.99109\n",
      "[560]\ttrain's auc: 0.986246\tvalid's auc: 0.991122\n",
      "[570]\ttrain's auc: 0.986259\tvalid's auc: 0.991125\n",
      "[580]\ttrain's auc: 0.986274\tvalid's auc: 0.991126\n",
      "[590]\ttrain's auc: 0.986289\tvalid's auc: 0.991131\n",
      "[600]\ttrain's auc: 0.986302\tvalid's auc: 0.991143\n",
      "[610]\ttrain's auc: 0.986313\tvalid's auc: 0.991144\n",
      "[620]\ttrain's auc: 0.986326\tvalid's auc: 0.991138\n",
      "[630]\ttrain's auc: 0.986339\tvalid's auc: 0.991145\n",
      "[640]\ttrain's auc: 0.986354\tvalid's auc: 0.991142\n",
      "[650]\ttrain's auc: 0.986365\tvalid's auc: 0.991142\n",
      "[660]\ttrain's auc: 0.986379\tvalid's auc: 0.991144\n",
      "[670]\ttrain's auc: 0.986392\tvalid's auc: 0.991146\n",
      "[680]\ttrain's auc: 0.986405\tvalid's auc: 0.99116\n",
      "[690]\ttrain's auc: 0.986418\tvalid's auc: 0.991159\n",
      "[700]\ttrain's auc: 0.986429\tvalid's auc: 0.991161\n",
      "[710]\ttrain's auc: 0.986443\tvalid's auc: 0.991153\n",
      "[720]\ttrain's auc: 0.986455\tvalid's auc: 0.991152\n",
      "[730]\ttrain's auc: 0.986468\tvalid's auc: 0.99116\n",
      "[740]\ttrain's auc: 0.986482\tvalid's auc: 0.991164\n",
      "[750]\ttrain's auc: 0.986494\tvalid's auc: 0.991162\n",
      "[760]\ttrain's auc: 0.986508\tvalid's auc: 0.991163\n",
      "[770]\ttrain's auc: 0.986523\tvalid's auc: 0.991172\n",
      "[780]\ttrain's auc: 0.986536\tvalid's auc: 0.991172\n",
      "[790]\ttrain's auc: 0.986549\tvalid's auc: 0.991178\n",
      "[800]\ttrain's auc: 0.98656\tvalid's auc: 0.991184\n",
      "[810]\ttrain's auc: 0.986572\tvalid's auc: 0.991179\n",
      "[820]\ttrain's auc: 0.986584\tvalid's auc: 0.99118\n",
      "[830]\ttrain's auc: 0.986597\tvalid's auc: 0.991189\n",
      "[840]\ttrain's auc: 0.986609\tvalid's auc: 0.991187\n",
      "[850]\ttrain's auc: 0.98662\tvalid's auc: 0.99119\n",
      "[860]\ttrain's auc: 0.986632\tvalid's auc: 0.991191\n",
      "[870]\ttrain's auc: 0.986642\tvalid's auc: 0.991183\n",
      "[880]\ttrain's auc: 0.986655\tvalid's auc: 0.991191\n",
      "[890]\ttrain's auc: 0.986666\tvalid's auc: 0.991192\n",
      "[900]\ttrain's auc: 0.986675\tvalid's auc: 0.991196\n",
      "[910]\ttrain's auc: 0.986687\tvalid's auc: 0.991195\n",
      "[920]\ttrain's auc: 0.986697\tvalid's auc: 0.991207\n",
      "[930]\ttrain's auc: 0.986707\tvalid's auc: 0.991212\n",
      "[940]\ttrain's auc: 0.986717\tvalid's auc: 0.99122\n",
      "[950]\ttrain's auc: 0.986727\tvalid's auc: 0.991217\n",
      "[960]\ttrain's auc: 0.986736\tvalid's auc: 0.991214\n",
      "[970]\ttrain's auc: 0.986748\tvalid's auc: 0.991215\n",
      "[980]\ttrain's auc: 0.986759\tvalid's auc: 0.991211\n",
      "[990]\ttrain's auc: 0.986774\tvalid's auc: 0.991205\n",
      "[1000]\ttrain's auc: 0.986786\tvalid's auc: 0.991208\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttrain's auc: 0.986786\tvalid's auc: 0.991208\n",
      "Plotting feature importances...\n",
      "Plotting auc curve...\n",
      "Plotting tree...\n",
      "Predicting...\n",
      "Projecting prediction onto test.csv...\n",
      "Creating output file...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "\n",
    "dtypes = {\n",
    "    'ip': 'uint32',\n",
    "    'app': 'uint16',\n",
    "    'device': 'uint16',\n",
    "    'os': 'uint16',\n",
    "    'channel': 'uint16',\n",
    "    'is_attributed': 'uint8',\n",
    "    'click_id': 'uint32',\n",
    "    }\n",
    "\n",
    "print('Loading train.csv...')\n",
    "train_cols = ['ip', 'app', 'device', 'os', 'channel', 'is_attributed', 'click_time']\n",
    "train_df = pd.read_csv('./data/train.csv', skiprows=range(1,64903891), nrows=120000000, dtype=dtypes, usecols=train_cols, parse_dates=['click_time'])\n",
    "\n",
    "print('Loading test_supplement.csv...')\n",
    "test_cols = ['ip', 'app', 'device', 'os', 'channel', 'click_id', 'click_time']\n",
    "test_df = pd.read_csv(\"./data/test_supplement.csv\", dtype=dtypes, usecols=test_cols, parse_dates=['click_time'])\n",
    "\n",
    "print('Preprocessing...')\n",
    "\n",
    "def add_counts(df, cols):\n",
    "    agg_name = \"_\".join(cols)+\"_count\"\n",
    "    arr_slice = df[cols].values\n",
    "    _, unqtags, counts = np.unique(np.ravel_multi_index(arr_slice.T, arr_slice.max(axis=0)+1),\n",
    "                                     return_inverse=True, return_counts=True)\n",
    "    df[agg_name] = counts[unqtags].astype('uint32')\n",
    "    del arr_slice\n",
    "    del unqtags\n",
    "    del counts\n",
    "    gc.collect()\n",
    "\n",
    "def do_countuniq(df, group_cols, counted):\n",
    "    agg_name= '{}_by_{}_countuniq'.format(('_'.join(group_cols)), (counted))\n",
    "    gp = df[group_cols+[counted]].groupby(group_cols)[counted].nunique().reset_index().rename(columns={counted:agg_name})\n",
    "    df = df.merge(gp, how='left', on=group_cols)\n",
    "    del gp\n",
    "    df[agg_name] = df[agg_name].astype('uint32')\n",
    "    gc.collect()\n",
    "    return df\n",
    "\n",
    "def add_next_click(df):\n",
    "    df['click_time'] = (df['click_time'].astype('int64') // 10 ** 9).astype('int32')\n",
    "    df['next_click'] = (df.groupby(['ip', 'app', 'device', 'os', 'channel']).click_time.shift(-1) - df.click_time).astype('float32')\n",
    "    df['next_click2'] = (df.groupby(['ip', 'app', 'device', 'os']).click_time.shift(-1) - df.click_time).astype('float32')\n",
    "    df['next_click3'] = (df.groupby(['ip', 'device', 'os']).click_time.shift(-1) - df.click_time).astype('float32')\n",
    "    df['click_time'] = pd.to_datetime(df['click_time'].astype('int64') * 10 ** 9)\n",
    "    gc.collect()\n",
    "\n",
    "def preproc_data(df):\n",
    "    \n",
    "    df['hour'] = df['click_time'].dt.hour.astype('uint8')\n",
    "    gc.collect()\n",
    "\n",
    "    print('Adding next_click features...')\n",
    "    add_next_click(df)\n",
    "    print(df.info())\n",
    "\n",
    "    print('Adding counts features...')\n",
    "    \n",
    "    df = do_countuniq(df, ['ip'], 'channel')\n",
    "    df = do_countuniq(df, ['ip'], 'app')\n",
    "    df = do_countuniq(df, ['ip', 'device', 'os'], 'app')\n",
    "    print(df.info())    \n",
    "\n",
    "    add_counts(df, ['ip'])\n",
    "    add_counts(df, ['os', 'app', 'channel'])\n",
    "    print(df.info())\n",
    "\n",
    "    add_counts(df, ['ip', 'hour'])\n",
    "    add_counts(df, ['ip', 'os', 'hour'])\n",
    "    add_counts(df, ['ip', 'device'])\n",
    "    print(df.info())\n",
    "\n",
    "    add_counts(df, ['ip', 'app', 'os'])\n",
    "    add_counts(df, ['hour', 'app'])\n",
    "    add_counts(df, ['channel', 'app'])\n",
    "    print(df.info())\n",
    "\n",
    "    return df\n",
    "\n",
    "y = train_df.is_attributed.values\n",
    "\n",
    "train_len = len(train_df)\n",
    "common_cols = ['ip', 'app', 'device', 'os', 'channel', 'click_time']\n",
    "train_df = pd.concat([train_df[common_cols], test_df[common_cols]])\n",
    "\n",
    "train_df = preproc_data(train_df)\n",
    "\n",
    "test_df = train_df.iloc[train_len:]\n",
    "train_df = train_df.iloc[:train_len]\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "lgb_params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'learning_rate': 0.15,\n",
    "    'num_leaves': 24,\n",
    "    'max_depth': 4,\n",
    "    'min_child_samples': 80,\n",
    "    'max_bin': 100,\n",
    "    'subsample': 0.65,\n",
    "    'subsample_freq': 1,\n",
    "    'colsample_bytree': 0.65,\n",
    "    'min_child_weight': 0,\n",
    "    'min_split_gain': 0,\n",
    "    'nthread': 4,\n",
    "    'verbose': 1,\n",
    "    'scale_pos_weight': 50\n",
    "}\n",
    "\n",
    "target = 'is_attributed'\n",
    "\n",
    "inputs = list(set(train_df.columns) - set([target, 'ip', 'click_time']))  \n",
    "cat_vars = ['app', 'device', 'os', 'channel', 'hour']\n",
    "\n",
    "train_df, val_df = train_test_split(train_df, train_size=0.98, shuffle=False)\n",
    "y_train, y_val = train_test_split(y, train_size=0.98, shuffle=False)\n",
    "\n",
    "print('Train size:', len(train_df))\n",
    "print('Valid size:', len(val_df))\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "print('Training...')\n",
    "\n",
    "xgtrain = lgb.Dataset(train_df[inputs].values, label=y_train, feature_name=inputs, categorical_feature=cat_vars)\n",
    "del train_df\n",
    "gc.collect()\n",
    "\n",
    "xgvalid = lgb.Dataset(val_df[inputs].values, label=y_val, feature_name=inputs, categorical_feature=cat_vars)\n",
    "del val_df\n",
    "gc.collect()\n",
    "\n",
    "eval_result = {}\n",
    "\n",
    "model = lgb.train(lgb_params,\n",
    "          xgtrain,\n",
    "          valid_sets= [xgtrain, xgvalid],\n",
    "          valid_names=['train', 'valid'],\n",
    "          num_boost_round=1000,\n",
    "          early_stopping_rounds=100,\n",
    "          evals_result=eval_result,\n",
    "          learning_rates=lambda iter: 0.15 if iter <=250 else 0.05,\n",
    "          verbose_eval=10)\n",
    "\n",
    "print('Plotting feature importances...')\n",
    "lgb.plot_importance(model)\n",
    "plt.savefig('./results/feature_importance.png', dpi=600, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "print('Plotting auc curve...')\n",
    "lgb.plot_metric(eval_result, metric='auc')\n",
    "plt.savefig('./results/auc_curve.png', dpi=600, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "print('Plotting tree...')\n",
    "lgb.plot_tree(model)\n",
    "plt.savefig('./results/tree.png', dpi=1200, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "del xgtrain\n",
    "del xgvalid\n",
    "gc.collect()\n",
    "\n",
    "print('Predicting...')\n",
    "test_df['is_attributed'] = model.predict(test_df[inputs])\n",
    "\n",
    "print('Projecting prediction onto test.csv...')\n",
    "test = pd.read_csv(\"./data/test.csv\", dtype=dtypes, usecols=test_cols, parse_dates=['click_time'])\n",
    "\n",
    "join_cols = ['ip', 'app', 'device', 'os', 'channel', 'click_time']\n",
    "all_cols = join_cols + ['is_attributed']\n",
    "\n",
    "test = test.merge(test_df[all_cols], how='left', on=join_cols)\n",
    "test = test.drop_duplicates(subset=['click_id'])\n",
    "\n",
    "print('Creating output file...')\n",
    "test[['click_id', 'is_attributed']].to_csv('./results/sokazaki.csv', index=False, float_format='%.9f')\n",
    "print('Done!')\n",
    "\n",
    "# public LB: 0.9808138, private LB: 0.9816301"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
